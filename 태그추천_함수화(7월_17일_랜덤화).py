# -*- coding: utf-8 -*-
"""태그추천 함수화(7월 17일_랜덤화).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KjAag6405xbFZRnaX9-JA4jimSkdOi2S
"""



# install

!pip install pymysql
!pip install konlpy
!pip install transformers

# 태그데이터 추출 함수화

import pymysql
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np

def get_data_from_db(host, port, user, password, database):
    connection = pymysql.connect(host=host, port=port, user=user, password=password, database=database)
    Playlist = pd.read_sql_query('SELECT * FROM playlist', connection)
    connection.close()
    return Playlist

def get_data_from_db_Song(host, port, user, password, database):
    connection = pymysql.connect(host=host, port=port, user=user, password=password, database=database)
    Playlist = pd.read_sql_query('SELECT * FROM song', connection)
    connection.close()
    return Playlist


def preprocess_data(Playlist, selected_column):
    Playlist['tag_list'] = Playlist[selected_column].apply(lambda x: [tag.strip() for tag in x.split(',')])
    return Playlist

def get_top_data(Playlist, num=109276):
    word_counts = Playlist['tag_list'].apply(lambda x: len(x))
    top_data = Playlist.iloc[word_counts.nlargest(num).index]
    return top_data

def tfidf_vectorization(top_data):
    tags = top_data[['tag_list']]
    tags['text'] = tags.apply(lambda row: ' '.join(row['tag_list']), axis=1)
    tfidf = TfidfVectorizer()
    tfidf_matrix_tag = tfidf.fit_transform(tags['text'])
    return tfidf, tfidf_matrix_tag

def get_top_words(tfidf, tfidf_matrix, top_n):
    feature_array = np.array(tfidf.get_feature_names_out())
    tfidf_sorting = np.argsort(tfidf_matrix.toarray())[:, ::-1]
    top_words_indices = tfidf_sorting[:, :top_n]
    top_words = [feature_array[indices] for indices in top_words_indices]
    result_df = pd.DataFrame(top_words, columns=[f'Top Word {i+1}' for i in range(top_n)])
    return result_df

Song = get_data_from_db_Song('34.64.95.29', 3306, 'root', 'acorn1234','music')
Playlist = get_data_from_db_Song('34.64.95.29', 3306, 'root', 'acorn1234','music')

def execute_pipeline_tags(host, port, user, password, database, selected_column, num=109276, top_n=100):
    # Get data from database
    Playlist = get_data_from_db(host, port, user, password, database)

    # Preprocess the data
    Playlist = preprocess_data(Playlist, selected_column)

    # Get top data
    top_data = get_top_data(Playlist, num)

    # Perform TF-IDF vectorization
    tfidf, tfidf_matrix_tag = tfidf_vectorization(top_data)

    # Get top words
    result_df_tag = get_top_words(tfidf, tfidf_matrix_tag, top_n)

    # result_df_tag.to_csv('/content/drive/MyDrive/train/tag_tf_idf_result.csv', index=False)


    return result_df_tag



result_df_tag = execute_pipeline_tags('34.64.95.29', 3306, 'root', 'acorn1234', 'music', 'tags', num=100, top_n=1)

# 타이틀데이터 함수화(전처리)

from sklearn.feature_extraction.text import TfidfVectorizer
from transformers import ElectraTokenizer, ElectraModel
from konlpy.tag import Okt
import torch
import pandas as pd
import re

def get_playlist_titles(Playlist, start=100, end=200):
    original = Playlist
    selected_cols = ['plylst_title']
    new_df_original = original[selected_cols]
    new_df_original['cleaned_column'] = new_df_original['plylst_title'].apply(lambda text: re.sub(r"[^a-zA-Z0-9\s가-힣]", "", text))
    selected_rows_title = new_df_original.iloc[start:end]
    new_df_title = pd.DataFrame(selected_rows_title)
    return new_df_title

def get_electra_embeddings(sentance_title):
    tokenizer = ElectraTokenizer.from_pretrained('monologg/koelectra-base-v3-discriminator')
    model = ElectraModel.from_pretrained('monologg/koelectra-base-v3-discriminator')
    extracted_words = []

    for row in sentance_title.itertuples():
        sentence = row[1]
        inputs = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True)
        model.eval()
        with torch.no_grad():
            outputs = model(**inputs)

        hidden_state = outputs[0]
        word_embeddings = hidden_state[0]
        threshold = 0.5

        extracted_sentence_words = []
        for idx, token in enumerate(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])):
            if token.startswith('##'):
                continue
            token_embedding = word_embeddings[idx]
            token_embedding_norm = torch.norm(token_embedding)
            if token_embedding_norm > threshold:
                extracted_sentence_words.append(token)

        extracted_words.append(extracted_sentence_words)
    return extracted_words

def extract_nouns_adjectives(sentance_title):
    def extract_words(text):
        tokenizer = Okt()
        words = []
        for word in tokenizer.pos(text):
            if word[1] in ['Noun','Adjective']:
                words.append(word[0])
        return words

    sentance_title['title_'] = sentance_title['text'].apply(extract_words)
    return sentance_title

def get_top_tfidf_words(sentance_title, top_n=1):
    # TF-IDF 벡터화 객체 생성
    tfidf = TfidfVectorizer()

    # TF-IDF 행렬 생성
    tfidf_matrix_title = tfidf.fit_transform(sentance_title['text'])

    # 중요도가 가장 높은 단어 N개 추출
    top_words_indices_title = tfidf_matrix_title.toarray().argsort(axis=1)[:, -top_n:]

    # 중요도가 가장 높은 단어들의 단어 목록 추출
    feature_names_title = tfidf.get_feature_names_out()
    top_words_title = [[feature_names_title[index] for index in indices] for indices in top_words_indices_title]

    # 결과 데이터프레임 생성
    context_df_title = pd.DataFrame(top_words_title, columns=[f'Top Word {i+1}' for i in range(top_n)])

    return context_df_title

def execute_electra_pipeline(Playlist, start=100, end=200, top_n=1):
    # Get playlist titles
    new_df_title = get_playlist_titles(Playlist, start, end)

    # Get ELECTRA embeddings
    extracted_words = get_electra_embeddings(new_df_title)

    # Convert the list of words to a single string
    extracted_words_str = [' '.join(words) for words in extracted_words]

    # Add the extracted words to the dataframe
    new_df_title['text'] = extracted_words_str

    # Extract nouns and adjectives
    new_df_title = extract_nouns_adjectives(new_df_title)

    # Get top TF-IDF words
    context_df_title = get_top_tfidf_words(new_df_title, top_n)

    #context_df_title.to_csv('/content/drive/MyDrive/train/title_tf_idf_result.csv', index=False, encoding = 'utf-8')

    return context_df_title

# ELECTRA 파이프라인을 실행하는 예시:
 # Substitute with your actual playlist titles

host = '34.64.95.29'
port = 3306
user = 'root'
password = 'acorn1234'
database = 'music'
start = 0
end = 100
top_n = 1

Playlist = get_data_from_db(host, port, user, password, database)

context_df_title = execute_electra_pipeline(Playlist, start, end, top_n)
context_df_title

# print(Playlist.dtypes)

# print(type(Playlist['plylst_title'].iloc[0]))

# print(Playlist['plylst_title'].isnull().sum())

# for i, text in enumerate(Playlist['plylst_title']):
#     try:
#         cleaned_text = re.sub(r"[^a-zA-Z0-9\s가-힣]", "", str(text))
#     except TypeError:
#         print(f"Error at index {i} with value {text}")



# Word2Word 적용 함수화

from gensim.models import Word2Vec

def apply_word2vec(df1, df2, columns, vector_size=4, window=3, min_count=1, workers=4):
    # Convert DataFrame columns to string
    feated_words1 = df1[columns].astype(str)
    feated_combined1 = feated_words1.apply(lambda row: ' '.join(row.values), axis=1)

    feated_words2 = df2[columns].astype(str)
    feated_combined2 = feated_words2.apply(lambda row: ' '.join(row.values), axis=1)

    # Create word2vec model
    model1 = Word2Vec(sentences=feated_combined1.str.split(), vector_size=vector_size, window=window, min_count=min_count, workers=workers)
    model2 = Word2Vec(sentences=feated_combined2.str.split(), vector_size=vector_size, window=window, min_count=min_count, workers=workers)

    # Average word vectors
    def average_word_vectors(words, model):
        word_vectors = [model.wv[word] for word in words if word in model.wv]
        return np.mean(word_vectors, axis=0)

    # Apply word vectors
    df1['vector'] = feated_combined1.apply(lambda x: average_word_vectors(x.split(' '), model1))
    df2['vector'] = feated_combined2.apply(lambda x: average_word_vectors(x.split(' '), model2))

    # Save models
    #model1.save('/content/drive/MyDrive/train/word2vec_model1.bin')
    #model2.save('/content/drive/MyDrive/train/word2vec_model2.bin')

    return df1, df2

# Word2Word 모델 로드 (코드)
# model1 = Word2Vec.load('/content/drive/MyDrive/train/word2vec_model1.bin')
# model2 = Word2Vec.load('/content/drive/MyDrive/train/word2vec_model2.bin')

result_df_tag, context_df_title = apply_word2vec(result_df_tag, context_df_title, ['Top Word 1'], vector_size=4, window=3, min_count=1, workers=4)



result_df_tag

context_df_title



from sklearn.metrics.pairwise import cosine_similarity

def extract_similar_words(result_df_tag, context_df_title, threshold=0.6):
    # 코사인 유사도 계산
    similarity_matrix = cosine_similarity(result_df_tag['vector'].tolist(), context_df_title['vector'].tolist())

    similar_tags_tag = []
    for i in range(similarity_matrix.shape[0]):
        similar_indices = np.where(similarity_matrix[i, :] > threshold)[0]
        similar_tags_tag.extend(result_df_tag['Top Word 1'].iloc[similar_indices].values)

    similar_tags_title = []
    for i in range(similarity_matrix.shape[0]):
        similar_indices = np.where(similarity_matrix[i, :] > threshold)[0]
        similar_tags_title.extend(context_df_title['Top Word 1'].iloc[similar_indices].values)

    # 매핑 데이터프레임 생성
    mapping_frame = pd.DataFrame({
        '태그': similar_tags_tag,
        '플레이리스트_타이틀(유저입력)': similar_tags_title,
    })

    # 열 데이터를 리스트로 변환
    tag_column_data = mapping_frame['태그'].tolist()
    title_column_data = mapping_frame['플레이리스트_타이틀(유저입력)'].tolist()

    # 코사인 유사도 계산 결과 반환
    cosine_similarity_scores = similarity_matrix.flatten().tolist()

    # 코사인 유사도 계산 결과 저장
    #np.save('/content/drive/MyDrive/train/cosine_similarity_scores.npy', cosine_similarity_scores)

    return tag_column_data, title_column_data

# 나중에 코사인 유사도 계산한것 로드(코드)
# np.load()

# 함수를 호출합니다.
tag_list, title_column_data = extract_similar_words(result_df_tag, context_df_title, threshold=1)

# 결과를 출력하거나 이후의 처리를 진행합니다.

def filter_playlist(tag_list, Playlist):
    # 이름변경
    target_word = tag_list

    # 검색
    filtered_ids = Playlist[Playlist['tags'].apply(lambda x: any([k in x for k in tag_list]))]['plylst_id'].tolist()

    # 검색해서 검색된 아이디만 데이터프레임으로
    # 필터링된 아이디에 해당하는 데이터만 추출
    filtered_Playlist = Playlist[Playlist['plylst_id'].isin(filtered_ids)][['plylst_id','tags', 'plylst_title_sc','songs']]

    return target_word,filtered_Playlist

target_word, filtered_Playlist = filter_playlist(tag_list, Playlist)
filtered_Playlist

target_word

import ast
import re

def preprocess_playlist(filtered_Playlist, target_word):
    def filter_tags(tags_text):
        # 문자열로 표현된 리스트를 실제 리스트로 변환
        tags = ast.literal_eval(tags_text)
        # target_word에 있는 단어만 남기기
        return [tag for tag in tags if tag in target_word]

    def remove_single_character_tags(tags):
        extracted_tags = re.findall(r"'(.*?)'", tags)
        return [tag for tag in extracted_tags if len(tag) > 1]

    # 'tags' 열에서 target_word만 남기기
    target_Playlist = filtered_Playlist.copy()
    target_Playlist['tags'] = target_Playlist['tags'].apply(filter_tags)

    # tag열 다시 텍스트로
    target_Playlist['tags'] = target_Playlist['tags'].apply(lambda tags: ', '.join(tags))

    # tags열에서 공백으로 되어있는 행 제거
    target_Playlist = target_Playlist[target_Playlist['tags'].str.strip() != '']

    # 'plylst_title_sc' 열에서 한 글자 단어가 있는 행 제거
    target_Playlist['plylst_title_sc'] = target_Playlist['plylst_title_sc'].apply(remove_single_character_tags)

    # 텍스트로 변환
    target_Playlist['plylst_title_sc'] = target_Playlist['plylst_title_sc'].apply(lambda x: ', '.join(x))

    # tags열에서 공백으로 되어있는 행 제거
    target_Playlist = target_Playlist[target_Playlist['plylst_title_sc'].str.strip() != '']

    # 텍스트가 없이 쉼표만 존재하는 데이터를 삭제
    target_Playlist['plylst_title_sc'] = target_Playlist['plylst_title_sc'].apply(lambda x: ', '.join(filter(None, x.split(', '))))

    # tags열에서 공백으로 되어있는 행 제거
    target_Playlist = target_Playlist[target_Playlist['plylst_title_sc'].str.strip() != '']

    return target_Playlist

# 함수를 호출합니다.
target_Playlist = preprocess_playlist(filtered_Playlist, target_word)

# 결과를 출력하거나 이후의 처리를 진행합니다.
target_Playlist

import pandas as pd
import spacy

def get_user_input(target_word):
    print("당신을 위해 추천된 카테고리입니다.:")
    for idx, word in enumerate(target_word):
        print(f"{idx+1}. {word}")
    selection = int(input("번호를 선택하여, 카테고리를 선택해주세요!: "))
    selected_tag = target_word[selection - 1]
    print("선택된 카테고리:", selected_tag)
    word = input("원하는 분위기를 입력하세요: ")
    return selected_tag, word

def find_most_similar_row(target_Playlist, selected_tag, word):
    nlp = spacy.load("en_core_web_sm")
    max_similarity = 0
    selected_row = None
    selected_index = None
    for index, row in target_Playlist.iterrows():
        if row['tags'] == selected_tag:
            for title_word in row['plylst_title_sc'].split(', '):
                similarity = nlp(word).similarity(nlp(title_word))
                if similarity > max_similarity:
                    max_similarity = similarity
                    selected_row = row
                    selected_index = index
    return selected_row, selected_index

def create_recommendation_df(selected_row):
    recommended = pd.DataFrame([selected_row])
    recommended['song_list'] = recommended['songs'].apply(lambda x: [tag.strip() for tag in x.split(',')])
    recommended_songs_list = recommended['songs'].values.tolist()
    recommended_songs_list = [int(num) for sublist in recommended_songs_list for num in sublist.split(', ')]
    return recommended_songs_list

def find_songs(recommended_songs_list, Song):
    Song_name = Song[Song['song_id'].isin(recommended_songs_list)]
    selected_cols = ['song_id','song_name','artist_name']
    Song_name_name = Song_name[selected_cols]
    return Song_name_name

selected_tag, word = get_user_input(target_word)
selected_row, selected_index = find_most_similar_row(target_Playlist, selected_tag, word)
recommended_songs_list = create_recommendation_df(selected_row)
Song_name_name = find_songs(recommended_songs_list, Song)

Song_name_name # 카테고리로 연애를 선택했고, # 키워드로 '헌신적인'을 입력하면? 짜안~!

# 이제 각 열을 리스트로 만들고 데이터베이스로 전송시켜준다면? 끝.

id_list = Song_name_name['song_id'].astype(int).tolist()
song_name_list = Song_name_name['song_name'].astype(str).tolist()
artist_name_list = Song_name_name['artist_name'].astype(str).tolist()

id_list